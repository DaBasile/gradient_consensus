% Template"Advanced control techniques" project

\documentclass[a4paper,11pt,oneside]{book}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb,amsmath,color,psfrag}
\usepackage[draft]{graphicx}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{comment}
\usepackage{listings}
\usepackage[svgnames]{xcolor}

\lstset{ 
    backgroundcolor=\color{white},   
    basicstyle=\scriptsize\rmfamily,        
    breaklines=true,                 
    captionpos=b,           
    numbers=left,
    numberstyle=\tiny\color{Gray},         
    commentstyle=\color{Green},  
    escapeinside={\%*}{*)},          
    keywordstyle=\color{Blue},       
    stringstyle=\color{Black},  
    frameround=ftff,
    language=python,  
    frame=single,
    belowcaptionskip=3em,
    belowskip=2em,
}


\begin{document}
\pagestyle{myheadings}

\input{cover}

\newpage
\thispagestyle{empty}

%%%%%% ABSTRACT %%%%%%%%%%
\begin{center}
\chapter*{}
\thispagestyle{empty}
{\Huge \textbf{Abstract}}\\
\vspace{15mm}
\end{center}
In this report, it will be shown how to solve a Multinomial Logistic Regression (also known as \textit{Softmax Regression}) using a distributed method. The sub-gradient method has been used to distribute calculations among a configurable number of agents. A portion of the dataset is given to each agent and used to minimize a cost function related to the portion of the dataset in its possession.

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents \thispagestyle{empty}
\listoffigures\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% INTRODUZIONE %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
In the past there was a single \textit{Mainframe} that executed all digital operations. Years after, with the creation of the Personal Computer, more people could execute the same operations in private. Today's \textit{Microcontrollers} allow to make smart an in finity of devices. More algorithms have been created to connect these devices to distribute.\\
This work implements a scenario in which there are some agents that estimate a cost function using their own information and those of the other agents; they use a \textit{Distributed Sub-gradient Method} to update their own estimate and, in particular, they resolve a \textit{Multinomial Logistic Regression}. After some test in \textit{MATLAB}, it is used \textit{MPI} implemented with \textit{Python}.\\
The present work is divided into two chapters. In Chapter 1, it is introduced the theory behind the problem and it is visualized and commented the implementation code. In Chapter 2 there are the results of simulations with some considerations.
% \section*{Organization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% CAPITOLO  %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Chapter 1 Problem and its implementation} \label{Cap1}
First-chapter for problem set-up and description of the implemented solution. 

\section{Theory of the problem} \label{Sec1.1}
\subsection {Distributed Subgradient Methods for Multi-Agent Optimization} \label{Subsec1.1.1}
In this problem there are $m$ agents that cooperatively minimize a common additive cost. The optimization general problem is:\\
\begin{equation} \label{costfunct}
minimize \quad \sum\limits_{i=1}^{m} f_{i} \left( x \right) \qquad subject \ to \quad x \in \mathbb{R}^n,
\end{equation}
where $f_i : \mathbb{R}^n \longrightarrow \mathbb{R}$ is the cost function of agent $i$, known by this agent only, and $x \in \mathbb{R}$ is a decision vector. It is assumes that:
\begin{itemize} 
\item The cost function is convex;
\item the agents are distributed over a time-varying topology;
\item the graph $\left(V,E_\infty\right)$ is connected, where $E_\infty$ is the set of edges $\left(j,i\right)$ representing agent pairs communicating directly infinitely many times;
\item there isn't communication delay.
\end{itemize} 
Every agent $i$ generates and maintains estimates of the optimal decision vector based on information concerning its own cost function and exchanges this estimate with its directly neighbors at discrete times $t_0, t_1, t_2, ...$. Moreover, each agent $i$ has a vector of weights $a^i(k) \in \mathbb{R}^m$ at any time $t_k$; for each time, the scalar $a_i^j(k)$ is zero if the agent $i$ doesn't directly comunicate with $j$, else it is the weight assigned from the agent $i$ to the information $x^j$ obtained from $j$ during the time interval $(t_k,t_{k+1})$. The estimates are updated according to the update rule:
\begin{equation} \label{update}
x^i\left(k+1\right) = \sum_{j=1}^{m}{a_j^i\left(k\right)x^i\left(k\right)-a^i\left(k\right)d_i\left(k\right)}
\end{equation}
where $\alpha^i(k)>0$ is the (diminishing) stepsize used by agent $i$ and the vector $d_i(k)$ is a subgradient of agent $i$ objective function $f_i(x)$ at $x=x^i(k)$. \cite{CITATION:1}

\subsection {Multinomial Logistic Regression} \label{Subsec1.1.2}
The problem to be solved is a Supervised Learning problem called Multinomial Logistic Regression, also known as Softmax Regression, and it generalizes the more common Logistic Regression. The difference between them is that in the latter there are several classes to be considered, in the matter, there are only two classes (or equivalently a binary class).\\
The problem to be solved is to find a set of coefficients based on a given dataset to predict the belonging class for an unseen set of features, while minimizing a cost function. The dataset is composed of \textit{N} labelled examples $\{(x^{(1)}, y^{(1)}), ..., (x^{(N)}, y^{(N)})\}$. Each $x^{(i)} \in R^{d_{x}}$ for $i=1, ..., N$ is composed of some features which represent the value upon which we base the estimation of the belonging class, while $y^{(i)} \in R^{d_{y}}$ is the belonging class for the \textit{i-th} example, and can be a values in $\{1, ..., K\}$.

Given a single training example $(x^{(i)}, y^{(i)})$, the definition of the cost function is:
\begin{equation}
f_i\left(\omega\right):=\left|\left|h_\omega\left(x^{(i)}\right)-y^{(i)}\right|\right|^2
\end{equation}
where the $\omega \in R^{d_{x}}$ are the weights of the hypothesis function $h_{\omega}$. The overall cost function can be defined as:
\begin{equation}
f\left(\omega\right):=\sum_{i=1}^{N}{f_i\left(\omega\right)}
\end{equation}
We solve the problem by finding the solution of the following optimization problem:
\begin{equation}
\omega^*:=\arg\min_\omega f\left(\omega\right)
\end{equation}
In the Multinomial Logistic Regression, a common choice for the hypothesis function is the following:
\begin{equation}
h_\theta=\frac{1}{\sum_{j=1}^{K}{exp\left(\theta^{(j)^\top}x\right)}}\begin{bmatrix}exp\left(\theta^{(1)\top}x\right)  \\ \vdots \\ exp\left(\theta^{(K)\top}x\right) \end{bmatrix}
\end{equation}
where the weights $\omega = \theta = (\theta^{(1)}, ..., \theta^{(K)}) \in R^{d_{x}}$. \\
Using this function, the solution of the problem is given by finding:
\begin{equation}
\theta^*=\arg\min_\theta -\sum_{i=1}^{N}{g_i(\theta)}
\end{equation}
with
\begin{equation}
g_i\left(\theta\right):=\sum_{k=1}^{K}{1\{y^{(i)}=e_k\}\log{\left( \frac{exp(\theta^{(k)^\top}x^{(i)})}{\sum_{k=1}^{K}{exp( \theta^{(j)^\top}x )}} \right)}}
\end{equation}
where \textbf{1\{$\cdot$\}} being the \textit{indicator function}.\cite{CITATION:2}

\subsection {Pseudocode} \label{Subsec1.1.3}
\begin{algorithm}
\caption{}
\begin{algorithmic} [1]
\State \textit{Stop Rules:}
\State $\left|\left|x_{k+1} - x_k\right|\right|  \leq \varepsilon \qquad \varepsilon$ fixed
\State Number of maximum iterations reached
\State \textbf{Start:}
\State Fix initial conditions for each node $x_i(0) = [0 \quad ... \quad 0]^T$
\State Define the Adjancency Matrix, Weights Matrix, $\alpha^i = \alpha$ constant for each iteration
\While{No stop rule is true, each node $i$ does:} 
	\State calculate $\nabla f_i$
	\For {each neighbor j}
		\State $x_i(k+1) = x_i(k+1) + a^i_j(k) x^j(k)$
	\EndFor
	\State $x_i(k+1) = x_i(k+1) - \alpha \nabla f_i$
\EndWhile
\State \textbf{Result:}
\State Each node $i$ should converge to $x^*$
\State The minimum of function is $\sum \limits_{i=1}^{m}f_i(x^*)$
\end{algorithmic}
\end{algorithm}


\section {Code Implementation} \label{Sec1.2}

Here we are defining and explaining what has been implemented in python order to solve the problem. The solution has been implemented using 
numpy library which computes all vector and matrix operation such as transposition, product, division, summation. Another library used is
networkx which create and manage connection agent by agent.\\

\subsection {create\_matrix.py}

The code implements random integer to create a random matrix to
compute quadratic functions; warning to warn some reading user that
can read some invalid value; networkx library to create directed graph
with its edges; numpy library to compute some matrix operation.
\begin{lstlisting}
from random import randint
from warnings import warn
import networkx as nx
import numpy as np
\end{lstlisting}


The \textit{createAdjM} function create a communication graph using world\_d as number of
mpi agents, n\_edges  setted by default as 1 if it is not given or
bigger than number of agent, phi that is simply a phase inserted into
graph which just shift the connection, by default is 0. The first for
cycle set the number of agents that the system has, then edges are
computed as follows:
\begin{itemize}
    \item The sum j + k + phi + 1 means the position of edge in the
    graph where item j is the current raw, k is the count of agent 
    that the agent j will send a message, phi is the phase and just
    shift the agent that j will send a message and the "+1" 

    \item The "if e $>=$ world\_d" istruction check if the sum is over the number of
    agents and if is true just subtract this one

    \item Instead "if e $==$ j" remove the ipotetical self loop unecessary .
\end{itemize}

\begin{lstlisting}
def createAdjM(world_d, n_edges=None, phi=None):

    if n_edges is None:
        n_edges = 1

    if n_edges > world_d or n_edges == 0:
        warn("Invalid n_edges entered... Setting to 1")
        n_edges = 1

    if phi is None:
        phi = 0

    if phi > world_d - 1:
        warn("Invalid phi entered... Setting to 0")
        phi = 0

    g = nx.DiGraph()

    for i in range(0, world_d):
        g.add_node(i)

    for j in range(0, world_d):

        for k in range(0, n_edges):

            e = j + k + phi + 1

            if e >= world_d:
                e = e - world_d

                if e == j:
                    e = e + 1

                    if e >= world_d:
                        e = e - world_d

                g.add_edge(j, e)

            else:
                g.add_edge(j, e)

    return g
\end{lstlisting}

\textit{createR} function create a random vector, to compute quadratic function, for each agent. This is used only for quadratic optimization.

\begin{lstlisting}
def createR(d):
    r = np.zeros((d, 1))

    for i in range(0, d):
        r[i] = randint(0, 1)

    return r
\end{lstlisting}

\textit{createQ} function create a random matrix, to compute quadratic function, for each agent. This is used only for quadratic optimization.

\begin{lstlisting}
def createQ(d):
    q = np.zeros((d, d))
    eye = np.identity(d)

    for i in range(0, d):

        for j in range(0, d):
            q[i][j] = randint(0, 2)

    a = np.add(q, np.transpose(q))
    a = np.add(a, np.dot(d, eye))

    return a
\end{lstlisting}

\subsection{functions.py}

This file has the gradient and loss functions for softmax regression, quadratic and exponential. The softmax regression is the implemented function
that has the task to compute the machine learning algorithm.

\begin{lstlisting}
import numpy as np
\end{lstlisting}

\textit{loss\_softmax} get as parameter the current state(\textit{all\_theta}), the cardinality of iris set (\textit{category\_count}), the agent
dataset (\textit{personal\_dataset}) and at least \textit{CONSTANT\_TO\_SUBTRACT}, is a constant to prevent overflow.\\
The algorithm wants to calculate the $\displaystyle\sum_{i=0}^{number\_of\_agents} f_{i}(x)$ and this function calculate the agent \textit{i}
$f(x)$. This can be done as follows: for every raw in the personal dataset, the algorithm compute the denominator that is the sum over all
exponential. Then compute category by category raw by raw the logarithm of ratio between the sum previously calculated and the exponential of raw.
After that there's the summation of all elements calculated.

\begin{lstlisting}
def loss_softmax(all_theta, category_count, personal_dataset, CONSTANT_TO_SUBTRACT):
    the_sum = 0

    for index in range(0, len(personal_dataset)):
        denominator = 0

        for theta in all_theta:
            denominator = denominator + np.exp(np.dot(theta, personal_dataset[index][0:4]) - CONSTANT_TO_SUBTRACT)

        for category in range(0, category_count):

            if category == personal_dataset[index][4]:
                _exp = np.exp(np.dot(all_theta[category], personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)
                _log = np.log(np.divide(_exp, denominator))
                the_sum = the_sum - _log

    return the_sum
\end{lstlisting}

\textit{gradient\_softmax} This is the gradient of softmax equation, that has the same concept as the function mentioned before: calculate in a
first time se sum of all exponential theta and then sum for each coefficient, subtract from one that coefficient and finally subtract the dataset
normalized with that to the respective theta.

\begin{lstlisting}
def gradient_softmax(all_theta, category_count):

    thetas = np.zeros(dimensions)

    for index in range(0, len(personal_dataset)):
        denominator = 0

        for theta in all_theta:
            denominator = denominator + np.exp(np.dot(theta, personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)

        for category in range(0, category_count):
            coeff = 0

            if category == personal_dataset[index][4]:
                coeff = 1

            _exp = np.exp(np.dot(all_theta[category], personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)
            coeff = coeff - np.divide(_exp, denominator)
            thetas[category] = thetas[category] - ((1/len(personal_dataset)) * np.multiply(personal_dataset[index][:4], coeff))

    return thetas
\end{lstlisting}

\subsection {working.py}

In this file is implemented the main algorithm where the consensus and the minimization is calculated.\\

To implement the consensus and minimization this import are needed:
\begin{itemize}
    \item \textit{mpi4py} is the mpi library for python which generates parallel simulated agent that compute all calculus.
    \item \textit{numpy} that implements matrix/vector computation
    \item \textit{matplotlib} which is the one whose cares about plotting results
    \item \textit{functions and create\_matrix} that are the previous file exposed
    \item \textit{time} that is needed to calculate the computational time of algorithm 
\end{itemize} 

Then complete iris training set is loaded, and environment variable are setted, as the number of agents, the name of $agent_{i}$.

\begin{lstlisting}
from mpi4py import MPI
import create_matrix as cm
import numpy as np
import matplotlib.pyplot as plt
import sys
import functions as func
import time


dataset = np.loadtxt('iris_training_complete.txt', delimiter=';', dtype=float)

""" Define world parameter, these have been got from mpi system """
world = MPI.COMM_WORLD
agents_number = world.Get_size()
rank = world.Get_rank()
\end{lstlisting}

Here are defined max number of iteration; dimensions is an array of [number of category, number of variables].

\begin{lstlisting}
""" Define variables """
MAX_ITERATIONS = 10000
category_n = 3
dimensions = [category_n, 4]
\end{lstlisting}

Then the dataset has been reparted in equal part to all agent and each one get's its one and print how many raw has.

\begin{lstlisting}
# Assign dataset to each agent
dataset_portion = len(dataset) / agents_number
start_dataset = rank * dataset_portion
end_dataset = (rank * dataset_portion) + dataset_portion
start_dataset = int(start_dataset)
end_dataset = int(end_dataset)
personal_dataset = dataset[start_dataset:end_dataset]

print("Agent ", rank, " got ", len(personal_dataset), " rows of dataset")

world.Barrier()
sys.stdout.flush()
\end{lstlisting}

Every agent create the same communication directed graph with number of agents and number of inn connection. Then state and loss variable are
created, setted to 0 of \textit{MAX\_ITERATIONS} size. In order to get wighted message, all in-neighbors are found and the variable \textit{weight}
is setted as the average. If the function name inserted is "quadratic" Q and r variables are created randomically. \textit{epsilon\_reached} and 
\textit{buff} are epsilon checker variable that say to agent when have to leave from loop (if epsilon is reached).

\begin{lstlisting}
adj = cm.createAdjM(agents_number, number_of_inn_connection)

x0 = np.ones(dimensions)

XX = np.zeros([MAX_ITERATIONS, *dimensions])
losses = np.zeros(MAX_ITERATIONS)
XX[0] = x0

num_of_neighbors = 0
for in_neighbors in adj.predecessors(rank):
    num_of_neighbors = num_of_neighbors + 1
weight = 1 / (num_of_neighbors + 1)  # 1 is for self-loop

world.Barrier()

if function_name == "quadratic":
    Q = cm.createQ(dimensions[1])
    r = cm.createR(dimensions[1])

epsilon_reached = False
buff = False

ITERATION_DONE = 0

start_time = time.time()
\end{lstlisting}

This for cycle calculate consensus. For every iters, is calculated the new "diminishing" alpha; message/messages are sended and received, then
local variable are weighted. In order to solve consensus to desiderated function, the three implemented one are inserted into an if clause, and the
right implemented function is called. After that the calculated gradient is multiplied to alpha and then new state is calculated. Then loss
function is called and if $\left\lVert XX[tt] - XX[tt-1] \right\rVert \leq epsilon$ then buff is true and rank 0 check if all agent has reched
epsilon condition, if true send a broadcast message with a true value to say to all that the cycle is done.

\begin{lstlisting}
for tt in range(1, MAX_ITERATIONS - 1):

    if alpha_type == "diminishing":
        alpha = psi_coefficient * (1 / tt) ** alpha_coefficient
    else:
        alpha = alpha_coefficient

    # Update with my previous state
    u_i = np.multiply(XX[tt - 1], weight)

    # Send the state to neighbors
    for node in adj.successors(rank):
        world.send(XX[tt - 1], dest=node)

    # Update with state of all nodes before me
    for node in adj.predecessors(rank):
        u_i = u_i + world.recv(source=node) * weight

    # Go in the opposite direction with respect to the gradient
    gradient = 0

    if function_name == "softmax":
        gradient = func.gradient_softmax(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

    elif function_name == "quadratic":
        gradient = func.gradient_quadratic(XX[tt - 1], category_n, dimensions, personal_dataset, Q, r)

    elif function_name == "exponential":
        gradient = func.gradient_exponential(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

     #print(gradient)

    grad = np.multiply(alpha, gradient)

    for i in range(0, dimensions[0]):
        u_i[i] = np.subtract(u_i[i], grad[i])

    # Store  my new state
    XX[tt] = u_i

    if function_name == "softmax":
        losses[tt] = func.loss_softmax(XX[tt], category_n, personal_dataset, CONSTANT_TO_SUBTRACT)

    elif function_name == "quadratic":
        losses[tt] = func.loss_quadratic(XX[tt], category_n, dimensions, personal_dataset, Q, r)

    elif function_name == "exponential":
        losses[tt] = func.loss_exponential(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

    # Checking epsilon reached condition
    if np.linalg.norm(np.subtract(XX[tt], XX[tt - 1])) < epsilon:
        buff = True

    # Rank 0 get all epsilon and check if all reached it
    buffer = world.gather(buff, root=0)

    # If true it set epsilon reached
    if rank == 0:
        if False not in buffer:
            epsilon_reached = True

    # Send epsilon reached to all agents
    epsilon_reached = world.bcast(epsilon_reached, root=0)

    # Check if all agent have reached epsilon condition and then exit from loop
    if epsilon_reached:
        if rank == 0:
            print("Exiting at iteration ", tt, "/", MAX_ITERATIONS, "Condition on epsilon reached")
            sys.stdout.flush()

        break

    if tt in range(0, MAX_ITERATIONS, 100):
        if rank == 0:
            print("Iteration ", tt, "/", MAX_ITERATIONS)
            sys.stdout.flush()
    ITERATION_DONE = tt
\end{lstlisting}

When consensus is reached value are printed to user, then all data are sended to rank 0 for centralized calculation

\begin{lstlisting}
print("Parameters of node ", rank)
print(XX[ITERATION_DONE - 3])

world.Barrier()
sys.stdout.flush()

if rank != 0:
    world.send(losses, dest=0)
    world.send(XX, dest=0)
\end{lstlisting}

After each agent has sent its own data, agent 0, collect and sum all loss function data. Then collect all \textit{ITERATION\_DONE} state of each
agent in a vector, which has been plotted leter. Before that plot coming out data has been converted into a logaritmic form.

\begin{lstlisting}
if rank == 0:

    # Take the losses from all the other agents and sum
    # We now have the overall loss given from the cost function
    for i in range(1, agents_number):
        agent_loss = world.recv(source=i)
        losses = np.add(losses, agent_loss)

    XX_agents = np.zeros([agents_number, *[MAX_ITERATIONS, *dimensions]])
    XX_agents[0] = XX
    for i in range(1, agents_number):
        XX_agents[i] = world.recv(source=i)

    log_losses = np.zeros(len(losses))
    for index in range(0, len(losses)-1):
        log_losses[index] = np.log(losses[index] - 8.945)

    # Plot cost function logarithmic
    plt.figure()
    plt.plot(range(0, ITERATION_DONE - 3), log_losses[0:ITERATION_DONE - 3])
    plt.title("$\sum_{i=0}^" + str(agents_number) + " f_i$")
    plt.show()

    # Plot cost function
    plt.figure()
    plt.plot(range(0, ITERATION_DONE - 3), losses[0:ITERATION_DONE - 3])
    plt.title("$\sum_{i=0}^" + str(agents_number) + " f_i$")
    plt.show()
    #plt.pause(100)
\end{lstlisting}

Here iris trainig is loaded to test if with the theta found are capable to predict the category of iris. An iteration along all iris trainig set
is launched, then for all category we implement the exponential about the product from the theta founded and current raw of the set. Then data has
been normalized and then the arg max is cought as predicted value, if it is not the right answer a variable \textit{wrong\_answer} is updated.

\begin{lstlisting}
if rank == 0:
    to_find = np.loadtxt('iris_training.txt', delimiter=';', dtype=float)
    # to_find = normalize_dataset(to_find)
    wrong_answers = 0
    for _set in to_find:
        _tot_exp = 0
        _tmp = np.zeros(4)
        for i in range(0, category_n):
            val = np.exp(np.dot(XX[ITERATION_DONE - 2][i], _set[0:4]) - CONSTANT_TO_SUBTRACT)
            _tmp[i] = val
            _tot_exp = _tot_exp + val
        _tmp = np.divide(_tmp, _tot_exp)
        _predicted = np.argmax(_tmp)
        # print('Predicted: ', _predicted, ', real: ', _set[4])
        if _predicted != _set[4]:
            wrong_answers = wrong_answers + 1

    print("Wrong predicted values: ", wrong_answers, "/", len(to_find))

    # Show consensus
    # for category in range(0, category_n):
    for component in range(0, 4):
        figure = plt.figure()
        for agent in range(0, agents_number):
            label = "Agent " + str(agent)
            plt.plot(range(0, ITERATION_DONE), XX_agents[agent][0:ITERATION_DONE, 0, component], label=label)
        plt.title("Component #" + str(component) + " of each $\Theta_{0}^{i}$")
        leg = plt.legend(loc='best', ncol=2, mode="expand", shadow=True, fancybox=True)
        leg.get_frame().set_alpha(0.5)
        plt.show()
    print("Iteration done: ", ITERATION_DONE, " Agent number: ", agents_number, "\nEpsilon: ", epsilon,
          " Const  Alpha: ", alpha_coefficient, " Const Psi ", psi_coefficient,
          "\nExecution time: ", time.time() - start_time, " Wrong preditions: ", wrong_answers)

    plt.pause(20)
    input("Press [enter] to continue.")
\end{lstlisting}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% CAPITOLO 2 %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Chapter 2 Results of simulations} \label{Cap2}
The software described in the previous chapter was used to solve a Multinomial Logistic Regression problem. Specifically, we classified the data of the Iris Dataset.

\section{Dataset, graph description and minimization function} \label{Sec2.1}
This dataset is composed of 150 instances, 120 used for training, the rest for tests. The instances contain 3 classes, each representing a type of Iris flower. Every instance has 4 features, sepal length, sepal width, petal length, petal width expressed in $cm$. We tried different types of graphs. These graphs are all strongly connected and the weight matrices for the nodes are doubly stochastic, as per the assumptions of convergence of the algorithm described in Chapter \ref{Cap1}. The results discussed in this chapter, if not differently noted, refer to cyclic graphs with a variable number of nodes. The program can minimize all kinds of loss functions. As shown in Chapter \ref{Sec1.2}, the quadratic and exponential functions can also be used. These last 2 functions don't guarantee useful results and/or convergence. The minimization function used in this chapter is the one described in Chapter \ref{Subsec1.1.2}, softmax.

\section{Performance} \label{Sec2.2}
There are some key factors that influence \textit{the computational time}, \textit{the numbers of iterations necessary} and \textit{the accuracy of the results}.\\

\subsection{Number of nodes} \label{Subsec2.2.1}
The Python program, thanks to the MPI platform, is capable of running on an arbitrary number of nodes. It was tested on as little as 2 nodes to as many as 60 nodes, which means that every node was processing the data of 2 instances (120 instances divided into 60 nodes). The best performances are obtained when the number of nodes corresponds to the number of physical cores of the machine where it runs. When the number of nodes exceeds greatly the number of physical cores, the resources are oversubscribed. In this case, the performances degrade notably as the nodes compete for cache and memory and the processors' schedulers are put in a difficult situation. On a 4-core test machine, a computation with 5000 iterations and 30 nodes is done in 5 minutes. The same machine can do the same number of iterations, but with 60 nodes, in 15 minutes. Therefore, the following tests will be shown on a 4 nodes setup. \\

\subsection{Epsilon} \label{Subsec2.2.2}
This is a small constant used as stop condition. If the result of the current calculation differs less than epsilon from the previous, the algorithm is stopped.

\subsection{Learning rate} \label{Subsec2.2.3}

\subsection{Fixed step-size} \label{Subsec2.2.4}
The step-size alpha plays a big role in the speed of convergence of the algorithm. There are 3 kinds of step-size. Fixed, diminishing and adaptive (Armijo). For reasons not discussed in this paper, it's not possible to use Armijo rule in a distributed problem. We will first deal with a simpler fixed step-size. With an epsilon equal to $0.001 (10^{-3})$:\\
\begin{tabularx}{\textwidth}{|X|X|X|X|}
\hline
\textbf{Value of fixed step-size} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o.30}\\
\hline
0.5 & 4601 & 6.8 & 1\\
\hline
0.1 & 2109 & 3.24 & 1\\
\hline
0.05 & 2342 & 3.68 & 0\\
\hline
0.01 & 1153 & 2.05 & 2\\
\hline
0.005 & 680 & 1.14 & 9\\
\hline
0.001 & 22 & 0.05 & 22\\
\hline
\end{tabularx}
%\begin{tabularx}{\textwidth}{|X|X|X|X|}
%%{\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Value of fixed step-size} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o.30}\\
%\hline
%0.5 & Not converging & & \\
%\hline
%0.1 & $>$50000 & $>$80 & 1\\
%\hline
%0.05 & $>$50000 & $>$80 & 1\\
%\hline
%0.01 & 2000 & 3 & 1\\
%\hline
%0.005 & 1600 & 2.4 & 1\\
%\hline
%0.001 & 2000 & 3.2 & 0\\
%\hline
%0.0005 & 1600 & 2.4 & 2\\
%\hline
%0.0001 & 500 & 0.8 & 13\\
%\hline
%\end{tabularx}
%%\end{tabular}
\\ \\
These results show a general truth about the step-size. If it is too little the learning process proceeds in a very slow way and it requires a huge amount of iterations. If the learning rate is too high and the gradient descent most probably will overshoot the minimum and not converges. Through trial and error, the step-size 0.001 was identified which allow reaching good performance and accuracy. In fact, in only 2.6 seconds, we can make predictions with no errors, using our 30 instances test dataset.

\subsection{Diminishing step-size} \label{Subsec2.2.5}
The diminishing step-size implemented in the code is in this form:\\
%\begin{equation}
%\alpha = const \dot \left( \frac{1}{tt} \right) exp(MATLAB)
%\end{equation}
Again, several tests were run by tweaking the constant and the exponent.\\ \\
\begin{tabularx}{\textwidth}{|X|X|X|X|X|}
\hline
\textbf{psi\_coeff} & \textbf{alpha\_exp coefficient} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o. 30}\\
\hline
1 & 0.01 & $>$20000 & $>$30 & 13\\
\hline
1 & 0.1 & 4033 & 6.66 & 1\\
\hline
0.1 & 0.01 & 2130 & 5.19 & 1\\
\hline
0.1 & 0.1 & 2028 & 3.07 & 0\\
\hline
0.01 & 0.01 & 1067 & 1.60 & 2\\
\hline
0.01 & 0.1 & 628 & 1 & 8\\
\hline
\end{tabularx}
%\begin{tabularx}{\textwidth}{|X|X|X|X|X|}
%\hline
%\textbf{Alpha\_const} & \textbf{Alpha\_exp} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o. 30}\\
%\hline
%1 & 0.01 & 96 & 0.14 & 13\\
%\hline
%1 & 0.1 & 132 & 0.25 & 1\\
%\hline
%0.1 & 0.01 & 1300 & 1.9 & 1\\
%\hline
%0.1 & 0.1 & $>$50000 & $>$80 & 1\\
%\hline
%0.01 & 0.01 & 1900 & 3.2 & 1\\
%\hline
%0.01 & 0.1 & $>$50000 & $>$80 & 1\\
%\hline
%\end{tabularx}
\\ \\
%\noindent The best result is obtained in only 132 iterations, with 1 and 0.1 as constant and exponent respectively. This is done in roughly a quarter of a second, obtaining only one error. The accuracy is worst then the previous result, but this is obtained in a fraction of the time needed to obtain 0 error with a fixed step-size. A difference of 2 or 3 seconds may not matter using the Iris Dataset, with a small amount of calculations. In a setup where a bigger number of calculations and bigger dataset are involved, one may prefer this slightly less accurate but faster approach. This graphs show the difference of the value calculated with the distributed algorithm and the...
The best result in term of accuracy is done with both parameters set to 0.1. The computation time is similar to the fixed-step size. \textit{Reducing the epsilon to 0.01, allow the program to reach consensus in 604 with parameters 0.01 and 0.1 and zero error.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% SVILUPPI FUTURI %%%%%%
\chapter*{Conclusions} % and future developments}
\addcontentsline{toc}{chapter}{Conclusions} %  and future developments}
In this work it has been resolved a Multinomial Logistic Regression problem using MPI in Python. Each agent used a Distributed Sub-gradient method to update its own estimate of optimal solution.
%% Tutte le considerazioni finali sintetiche si fanno in base alla tabella dei risultati del capitolo 2.
%%%%%%%%%%%%%%%%%%%%%%%%%%

% %%%% APPENDIX %%%%%
% \appendix
% \chapter{Appendix title}
% %%%%%%%%%%%%%%%%%%%%

%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%
\bibliography{bibliography}{}
\bibliographystyle{plain}	
\addcontentsline{toc}{chapter}{Bibliography}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
