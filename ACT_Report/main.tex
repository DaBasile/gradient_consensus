% Template"Advanced control techniques" project

\documentclass[a4paper,11pt,oneside]{book}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb,amsmath,color,psfrag}
\usepackage[draft]{graphicx}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{comment}
\usepackage{listings}
\usepackage[svgnames]{xcolor}

\lstset{ 
    backgroundcolor=\color{white},   
    basicstyle=\scriptsize\rmfamily,        
    breaklines=true,                 
    captionpos=b,           
    numbers=left,
    numberstyle=\tiny\color{Gray},         
    commentstyle=\color{Green},  
    escapeinside={\%*}{*)},          
    keywordstyle=\color{Blue},       
    stringstyle=\color{Black},  
    frameround=ftff,
    language=python,  
    frame=single,
    belowcaptionskip=3em,
    belowskip=2em,
}


\begin{document}
\pagestyle{myheadings}

\input{cover}

\newpage
\thispagestyle{empty}

%%%%%% ABSTRACT %%%%%%%%%%
\begin{center}
\chapter*{}
\thispagestyle{empty}
{\Huge \textbf{Abstract}}\\
\vspace{15mm}
\end{center}
In this report, it will be shown how to solve a Multinomial Logistic Regression (also known as \textit{Softmax Regression}) using a distributed method. The sub-gradient method has been used to distribute calculations among a configurable number of agents. A portion of the dataset is given to each agent and used to minimize a cost function related to the portion of the dataset in its possession.

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents \thispagestyle{empty}
\listoffigures\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% INTRODUZIONE %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
In the past there was a single \textit{Mainframe} that executed all digital computations. Years after, with the creation of the Personal Computer, more people could execute the same operations in private. Today's \textit{Microcontrollers} allow to make smart an infinity of devices. More algorithms have been created to connect these devices to distribute.\\
This work implements a scenario in which there are some agents that estimate a cost function using their own information and those of the other agents; they use a \textit{Distributed Sub-gradient Method} to update their own estimate and, in particular, they resolve a \textit{Multinomial Logistic Regression}. After some test in \textit{MATLAB}, it is used \textit{MPI} implemented with \textit{Python}.\\
The present work is divided into two chapters. In Chapter \ref{Cap1}, it is introduced the theory behind the problem and it is visualized and commented the implementation code. In Chapter \ref{Cap2} there are the results of simulations with some considerations.
% \section*{Organization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% CAPITOLO  %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Chapter 1 Problem and its implementation} \label{Cap1}

\section{Theory of the problem} \label{Sec1.1}
\subsection {Distributed Subgradient Methods for Multi-Agent Optimization} \label{Subsec1.1.1}
In this problem there are $m$ agents that cooperatively minimize a common additive cost. The general optimization problem is:\\
\begin{equation} \label{costfunct}
minimize \quad \sum\limits_{i=1}^{m} f_{i} \left( x \right) \qquad subject \ to \quad x \in \mathbb{R}^n,
\end{equation}
where $f_i : \mathbb{R}^n \longrightarrow \mathbb{R}$ is the cost function of agent $i$, known only by this agent, and $x \in \mathbb{R}$ is a decision vector. It is assumed that:
\begin{itemize} 
\item the cost function is convex;
\item the agents are distributed over a time-varying topology;
\item the graph $\left(V,E_\infty\right)$ is connected, where $E_\infty$ is the set of edges $\left(j,i\right)$ representing agent pairs communicating directly an indefinite number of times;
\item there isn't communication delay.
\end{itemize} 
Every agent $i$ generates and maintains estimates of the optimal decision vector based on information concerning its own cost function and exchanges this estimate with its directly neighbors at discrete times $t_0, t_1, t_2, ...$. Moreover, each agent $i$ has a vector of weights $a^i(k) \in \mathbb{R}^m$ at any time $t_k$; the scalar $a_i^j(k)$ is zero if the agent $i$ doesn't directly communicate with $j$, else it is the weight assigned from the agent $i$ to the information $x^j$ obtained from $j$ during the time interval $(t_k,t_{k+1})$. The estimates are updated according to the update rule:
\begin{equation} \label{update}
x^i\left(k+1\right) = \sum_{j=1}^{m}{a_j^i\left(k\right)x^i\left(k\right)-a^i\left(k\right)d_i\left(k\right)}
\end{equation}
where $\alpha^i(k)>0$ is the stepsize used by agent $i$ and the vector $d_i(k)$ is a subgradient of agent $i$ objective function $f_i(x)$ at $x=x^i(k)$. \cite{CITATION:1}

\subsection {Multinomial Logistic Regression} \label{Subsec1.1.2}
The problem to be solved is a Supervised Learning problem called Multinomial Logistic Regression, also known as Softmax Regression, and it generalizes the more common Logistic Regression. The difference between them is that in the former there are several classes to be considered, in the latter, there are only two classes (or equivalently a binary class).\\
The problem to be solved is to find a set of coefficients based on a given dataset to predict the belonging class for an unseen set of features, while minimizing a cost function. The dataset is composed of \textit{N} labelled examples $\{(x^{(1)}, y^{(1)}), ..., (x^{(N)}, y^{(N)})\}$. Each $x^{(i)} \in R^{d_{x}}$ for $i=1, ..., N$ is composed of some features which represent the value upon which we base the estimation of the belonging class, while $y^{(i)} \in R^{d_{y}}$ is the belonging class for the \textit{i-th} example, and can be a values in $\{1, ..., K\}$.

Given a single training example $(x^{(i)}, y^{(i)})$, the definition of the cost function is:
\begin{equation}
f_i\left(\omega\right):=\left|\left|h_\omega\left(x^{(i)}\right)-y^{(i)}\right|\right|^2
\end{equation}
where the $\omega \in R^{d_{x}}$ are the weights of the hypothesis function $h_{\omega}$. The overall cost function can be defined as:
\begin{equation}
f\left(\omega\right):=\sum_{i=1}^{N}{f_i\left(\omega\right)}
\end{equation}
We solve the problem by finding the solution of the following optimization problem:
\begin{equation}
\omega^*:=\arg\min_\omega f\left(\omega\right)
\end{equation}
In the Multinomial Logistic Regression, a common choice for the hypothesis function is the following:
\begin{equation}
h_\theta=\frac{1}{\sum_{j=1}^{K}{exp\left(\theta^{(j)^\top}x\right)}}\begin{bmatrix}exp\left(\theta^{(1)\top}x\right)  \\ \vdots \\ exp\left(\theta^{(K)\top}x\right) \end{bmatrix}
\end{equation}
where the weights $\omega = \theta = (\theta^{(1)}, ..., \theta^{(K)}) \in R^{d_{x}}$. \\
Using this function, the solution of the problem is given by finding:
\begin{equation}
\theta^*=\arg\min_\theta -\sum_{i=1}^{N}{g_i(\theta)}
\end{equation}
with
\begin{equation}
g_i\left(\theta\right):=\sum_{k=1}^{K}{1\{y^{(i)}=e_k\}\log{\left( \frac{exp(\theta^{(k)^\top}x^{(i)})}{\sum_{k=1}^{K}{exp( \theta^{(j)^\top}x )}} \right)}}
\end{equation}
where \textbf{1\{$\cdot$\}} being the \textit{indicator function}.\cite{CITATION:2}

\subsection {Pseudocode} \label{Subsec1.1.3}
\begin{algorithm}
\caption{}
\begin{algorithmic} [1]
\State \textit{Stop Rules:}
\State $\left|\left|\theta_{k+1} - \theta_k\right|\right|  \leq \varepsilon \qquad \varepsilon$ fixed
\State Number of maximum iterations reached
\State \textbf{Start:}
\State Fix initial conditions for each node $\theta_i(0) = [0 \quad ... \quad 0]^T$
\State Define the Adjacency Matrix, Weights Matrix, $\alpha^i = \alpha$ constant for each iteration
\While{No stop rule is true, each node $i$ does:} 
    \State calculate $\nabla f_i$
    \For {each neighbor j}
        \State $\theta_i(k+1) = \theta_i(k+1) + a^i_j(k) \theta^j(k)$
    \EndFor
    \State $\theta_i(k+1) = \theta_i(k+1) - \alpha \nabla f_i$
\EndWhile
\State \textbf{Result:}
\State Each node $i$ should converge to $\theta^*$
\State The minimum of function is $\sum \limits_{i=1}^{m}f_i(x^*)$
\end{algorithmic}
\end{algorithm}


\section {Code Implementation} \label{Sec1.2}

Here we are defining and explaining what has been implemented in Python to solve the problem. The solution has been
implemented using: $numpy$ library which computes all vector and matrix operation such as transposition, product, division,
summation; $networkx$ which creates and manage adjacency matricies for all agent; $matplotlib$ that create and plot result
which we have cought during test and training phase. At a first time the code check if any parameter are send to every agent,
then start to create environment, such as get the number of agent, create adjacency matrix and initialize local variable where
it will save collected data. The weights depends about how many in-neighbors each agent has, because our adjacency matrix is
setted with k in-neighbors that can be setted when program is launched. \\

The adjacency matrix is created by \textit{createAdjM} function, that make a communication graph using world\_d as number of
mpi agents, n\_edges  setted by default as 1 (if it is not given or
bigger than number of agent), phi that is simply a phase inserted into
graph which just shift the connection, by default is 0. The first $for$
cycle sets the number of agents that the system has, then edges are
computed as follows:
\begin{itemize}
    \item The sum j + k + phi + 1 means the position of edge in the
    graph where item j is the current row, k is the count of agent 
    that the agent j will send a message, phi is the phase and just
    shift the agent that j will send a message and the "+1" 

    \item The instruction $ if \ e >= world\_d $  check if the sum is over the number of
    agents and if is true just subtracts this one

    \item Instead $ if \ e \ $==$ \  j $ removes the ipotetical unnecessary self loop.
\end{itemize}


Loss softmax function,\textit{loss\_softmax} gets as parameter the current state(\textit{all\_theta}), the cardinality of
iris set (\textit{category\_count}), the agent dataset (\textit{personal\_dataset}) and a \textit{CONSTANT\_TO\_SUBTRACT}, a
constant to prevent overflow.\\
The algorithm wants to calculate the $\displaystyle\sum_{i=0}^{number\_of\_agents} f_{i}(x)$ and this function calculate the
agent \textit{i} $f(x)$. This can be done as follows: for every row in the personal dataset, the algorithm computes the
denominator that is the sum over all exponential. Then it computes, category by category, row by row, the logarithm of ratio
between the sum previously calculated and the exponential of the row. After that, there's the summation of all calculated
elements.

\begin{lstlisting}
def loss_softmax(all_theta, category_count, personal_dataset, CONSTANT_TO_SUBTRACT):
    the_sum = 0

    for index in range(0, len(personal_dataset)):
        denominator = 0

        for theta in all_theta:
            denominator = denominator + np.exp(np.dot(theta, personal_dataset[index][0:4]) - CONSTANT_TO_SUBTRACT)

        for category in range(0, category_count):

            if category == personal_dataset[index][4]:
                _exp = np.exp(np.dot(all_theta[category], personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)
                _log = np.log(np.divide(_exp, denominator))
                the_sum = the_sum - _log

    return the_sum
\end{lstlisting}

The gradient method implemented here, called \textit{gradient\_softmax} This is the gradient of softmax equation, that has
the same concept as the function mentioned before: calculate in a first time se sum of all exponential theta and then sum for
each coefficient, subtract from one that coefficient and finally subtract the dataset normalized with that to the respective
theta.

\begin{lstlisting}
def gradient_softmax(all_theta, category_count):

    thetas = np.zeros(dimensions)

    for index in range(0, len(personal_dataset)):
        denominator = 0

        for theta in all_theta:
            denominator = denominator + np.exp(np.dot(theta, personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)

        for category in range(0, category_count):
            coeff = 0

            if category == personal_dataset[index][4]:
                coeff = 1

            _exp = np.exp(np.dot(all_theta[category], personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)
            coeff = coeff - np.divide(_exp, denominator)
            thetas[category] = thetas[category] - ((1/len(personal_dataset)) * np.multiply(personal_dataset[index][:4], coeff))

    return thetas
\end{lstlisting}

\subsection {working.py}

In this file is implemented the main algorithm where the consensus and the minimization of loss function is calculated.\\

The complete iris training set is loaded, and environment variables are setted, as the number of agents, the name of $agent_{i
}$. Then the dataset is splitted equal parts to all agents and each one gets its one and print how many row it has.

Every agent creates the same communication directed graph with number of agents and number of in connection. Then state and
loss variable are created, setted to 0 of \textit{MAX\_ITERATIONS} size. In order to get wighted message, all in-neighbors
are found and the variable \textit{weight} is setted as the average. If the function name inserted is "quadratic" Q and r
variables are created randomly. \textit{epsilon\_reached} and \textit{buff} are epsilon checker variable that say to agent
when they have to exit from the loop (if epsilon is reached).


This $for$ cycle calculates the consensus. For every $iters$, is calculated the new "diminishing" alpha; message(s) are sent
and received, then local variable are weighted. In order to solve consensus to desiderated function, the three implemented
ones are inserted into an $if$ clause, and the right function is called. After that, the calculated gradient is multiplied by
alpha and then new state is calculated. Then $loss function$ is called and if $\left\lVert XX[tt] - XX[tt-1] \right\rVert
\leq epsilon$ then buff is true and rank 0 check if all agent has reched the epsilon condition; if true it sends a broadcast 
message with a $true$ value to say to all that the cycle is done.

\begin{lstlisting}
for tt in range(1, MAX_ITERATIONS - 1):

    if alpha_type == "diminishing":
        alpha = psi_coefficient * (1 / tt) ** alpha_coefficient
    else:
        alpha = alpha_coefficient

    # Update with my previous state
    u_i = np.multiply(XX[tt - 1], weight)

    # Send the state to neighbors
    for node in adj.successors(rank):
        world.send(XX[tt - 1], dest=node)

    # Update with state of all nodes before me
    for node in adj.predecessors(rank):
        u_i = u_i + world.recv(source=node) * weight

    # Go in the opposite direction with respect to the gradient
    gradient = 0

    if function_name == "softmax":
        gradient = func.gradient_softmax(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

    elif function_name == "quadratic":
        gradient = func.gradient_quadratic(XX[tt - 1], category_n, dimensions, personal_dataset, Q, r)

    elif function_name == "exponential":
        gradient = func.gradient_exponential(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

     #print(gradient)

    grad = np.multiply(alpha, gradient)

    for i in range(0, dimensions[0]):
        u_i[i] = np.subtract(u_i[i], grad[i])

    # Store  my new state
    XX[tt] = u_i

    if function_name == "softmax":
        losses[tt] = func.loss_softmax(XX[tt], category_n, personal_dataset, CONSTANT_TO_SUBTRACT)

    elif function_name == "quadratic":
        losses[tt] = func.loss_quadratic(XX[tt], category_n, dimensions, personal_dataset, Q, r)

    elif function_name == "exponential":
        losses[tt] = func.loss_exponential(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

    # Checking epsilon reached condition
    if np.linalg.norm(np.subtract(XX[tt], XX[tt - 1])) < epsilon:
        buff = True

    # Rank 0 get all epsilon and check if all reached it
    buffer = world.gather(buff, root=0)

    # If true it set epsilon reached
    if rank == 0:
        if False not in buffer:
            epsilon_reached = True

    # Send epsilon reached to all agents
    epsilon_reached = world.bcast(epsilon_reached, root=0)

    # Check if all agent have reached epsilon condition and then exit from loop
    if epsilon_reached:
        if rank == 0:
            print("Exiting at iteration ", tt, "/", MAX_ITERATIONS, "Condition on epsilon reached")
            sys.stdout.flush()

        break

    if tt in range(0, MAX_ITERATIONS, 100):
        if rank == 0:
            print("Iteration ", tt, "/", MAX_ITERATIONS)
            sys.stdout.flush()
    ITERATION_DONE = tt
\end{lstlisting}

When consensus is reached, the theta values are printed to user, then all data are sent to rank 0 for centralized
calculations and plot result.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% CAPITOLO 2 %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Chapter 2 Results of simulations} \label{Cap2}
The software described in the previous chapter was used to solve a Multinomial Logistic Regression problem. Specifically, we classified the data of the Iris Dataset.

\section{Dataset, graph description and minimization function} \label{Sec2.1}
This dataset is composed of 150 instances, 120 used for training, the rest for tests. The instances contain 3 classes, each representing a type of Iris flower. Every instance has 4 features, sepal length, sepal width, petal length, petal width expressed in $cm$. We tried different types of graphs. These graphs are all strongly connected and the weight matrices for the nodes are doubly stochastic, as per the assumptions of convergence of the algorithm described in Chapter \ref{Cap1}. The results discussed in this chapter, if not differently noted, refer to cyclic graphs with a variable number of nodes. The program can minimize all kinds of loss functions. As shown in Chapter \ref{Sec1.2}, the quadratic and exponential functions can also be used. These last 2 functions don't guarantee useful results and/or convergence. The minimization function used in this chapter is the one described in Chapter \ref{Subsec1.1.2}, softmax.

\section{Performance} \label{Sec2.2}
There are some key factors that influence \textit{the computational time}, \textit{the numbers of iterations necessary} and \textit{the accuracy of the results}.\\

\subsection{Number of nodes} \label{Subsec2.2.1}
The Python program, thanks to the MPI platform, is capable of running on an arbitrary number of nodes. It was tested on as little as 2 nodes to as many as 60 nodes, which means that every node was processing the data of 2 instances (120 instances divided into 60 nodes). The best performances are obtained when the number of nodes corresponds to the number of physical cores of the machine where it runs. When the number of nodes exceeds greatly the number of physical cores, the resources are oversubscribed. In this case, the performances degrade notably as the nodes compete for cache and memory and the processors' schedulers are put in a difficult situation. On a 4-core test machine, a computation with 5000 iterations and 30 nodes is done in 5 minutes. The same machine can do the same number of iterations, but with 60 nodes, in 15 minutes. Therefore, the following tests will be shown on a 4 nodes setup. \\

\subsection{Epsilon} \label{Subsec2.2.2}
This is a small constant used as stop condition. If the result of the current calculation differs less than epsilon from the previous, the algorithm is stopped.

\subsection{Learning rate} \label{Subsec2.2.3}
The step-size alpha plays a big role in the speed of convergence of the algorithm. There are 3 kinds of step-size. Fixed, diminishing and adaptive (Armijo). For reasons not discussed in this paper, it's not possible to use Armijo rule in a distributed problem.

\subsection{Fixed step-size} \label{Subsec2.2.4}
 We will first deal with a simpler fixed step-size. With an epsilon equal to $0.001\  (10^{-3})$:\\
\begin{tabularx}{\textwidth}{|X|X|X|X|}
\hline
\textbf{Value of fixed step-size} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o.30}\\
\hline
0.5 & overflow & alpha too big & -\\
\hline
0.1 & \textgreater 10000 & \textgreater 15 & 2\\
\hline
0.05 & \textgreater 10000 & \textgreater 15 & 1\\
\hline
0.01 & 1968 & 2.8 & 1\\
\hline
0.005 & 1558 & 2.3 & 1\\
\hline
0.001 & 2114 & 3.1 & 0\\
\hline
0.0005 & 1619 & 2.3 & 2\\
\hline
0.0001 & 527 & 0.7 & 14\\
\hline
\end{tabularx}

\\ \\
These results show a general truth about the step-size. If it is too little, the learning process proceeds in a very slow way and it requires a huge amount of iterations. If the learning rate is too high, the gradient descent will most probably overshoot the minimum and it will not converge. Through trial and error, the step-size 0.001 was identified, it allows reaching good performance and accuracy. In fact, in only 3.1 seconds, we can make predictions with no errors, using our 30 instances test dataset.

\subsection{Diminishing step-size} \label{Subsec2.2.5}
The diminishing step-size implemented in the code is in this form:
TODO: SISTEMARE
\\
\begin{equation}
\alpha = const \dot \left( \frac{1}{tt} \right) exp
\end{equation}
Again, several tests were run by tweaking the multiplying constant and the exponent.\\ \\
\begin{tabularx}{\textwidth}{|X|X|X|X|X|}
\hline
\textbf{psi\_coeff} & \textbf{alpha\_exp coefficient} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o. 30}\\
\hline
1 & 0.01 & overflow & - & -\\
\hline
1 & 0.1 & overflow & - & -\\
\hline
0.1 & 0.01 & \textgreater 10000 & \textgreater 15 & 1\\
\hline
0.1 & 0.5 & 349 & 0.5 & 0\\
\hline
0.1 & 0.1 & \textgreater 10000 & \textgreater 16 & 1\\
\hline
0.01 & 0.01 & 1852 & 2.7 & 1\\
\hline
0.01 & 0.1 & 1259 & 1.8 & 1\\
\hline
\end{tabularx}

\\ \\
\noindent The best result is obtained in only 349 iterations, with 0.1 and 0.5 as multiplicative constant and exponent respectively. This is done in roughly half of a second, obtaining no error. The accuracy is worst then the previous result, but this is obtained in a fraction of the time needed to obtain 0 error with a fixed step-size. A difference of 2 or 3 seconds may not seem important using the Iris Dataset, with a small amount of calculations. In a setup where a bigger number of calculations and bigger dataset are involved, one may appreciate the advantages of this faster approach.




TODO: GRAFICI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% SVILUPPI FUTURI %%%%%%
\chapter*{Conclusions} % and future developments}
\addcontentsline{toc}{chapter}{Conclusions} %  and future developments}
In this work it has been resolved a Multinomial Logistic Regression problem using MPI in Python. Each agent used a Distributed Sub-gradient method to update its own estimate of optimal solution.
%% Tutte le considerazioni finali sintetiche si fanno in base alla tabella dei risultati del capitolo 2.
%%%%%%%%%%%%%%%%%%%%%%%%%%

% %%%% APPENDIX %%%%%
% \appendix
% \chapter{Appendix title}
% %%%%%%%%%%%%%%%%%%%%

%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%
\bibliography{bibliography}{}
\bibliographystyle{plain}   
\addcontentsline{toc}{chapter}{Bibliography}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
