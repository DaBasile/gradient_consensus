% Template"Advanced control techniques" project

\documentclass[a4paper,11pt,oneside]{book}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb,amsmath,color,psfrag}
\usepackage[draft]{graphicx}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{comment}
\usepackage{listings}
\usepackage[svgnames]{xcolor}
\usepackage{subcaption}

\lstset{ 
    backgroundcolor=\color{white},   
    basicstyle=\scriptsize\rmfamily,        
    breaklines=true,                 
    captionpos=b,           
    numbers=left,
    numberstyle=\tiny\color{Gray},         
    commentstyle=\color{Green},  
    escapeinside={\%*}{*)},          
    keywordstyle=\color{Blue},       
    stringstyle=\color{Black},  
    frameround=ftff,
    language=python,  
    frame=single,
    belowcaptionskip=3em,
    belowskip=2em,
}


\begin{document}
\pagestyle{myheadings}

\input{cover}

\newpage
\thispagestyle{empty}

%%%%%% ABSTRACT %%%%%%%%%%
\begin{center}
\chapter*{}
\thispagestyle{empty}
{\Huge \textbf{Abstract}}\\
\vspace{15mm}
\end{center}
In this report, it will be shown how to solve a Multinomial Logistic Regression (also known as \textit{Softmax Regression}) using a distributed method. The sub-gradient method has been used to distribute calculations among a configurable number of agents. A portion of the dataset is given to each agent and used to minimize a cost function related to the portion of the dataset in its possession.
A Python3 program has been written supported by several libraries. The most important library is MPI4py which provides implementation of the MPI specifics. MPI is a communication protocol between nodes that executes the same program in parallel. We compared the results obtained through this program with MATLAB script which executes all operation with  a centralized architecture ( meaning that all operations are executed by a single agent).\\
Several graphs are plotted in order to see the graph of communicating agents, how the consensus is reached and how the cost diminishes to a minimum.

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents \thispagestyle{empty}
\listoffigures\thispagestyle{empty}

%%%%%% INTRODUZIONE %%%%%%%%%%
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\section*{Motivations}
In the past there was a single \textit{Mainframe} that executed all digital computations. Years after, with the creation of the Personal Computer, more people could execute the same operations in private. Today's \textit{Microcontrollers} allow to make smart all the of devices. More algorithms have been created to connect these devices to distribute.\\
 In general, this approach is useful because it allows cooperation between agents, to reach a common goal. In this case, the ability to split the workload in to several agents guarantees faster execution times.
The Multinomial Logistic Regression generalizes the logistic regression for a multiclass problem, with more than two possible discrete outcomes, where each observation has several features.

\section*{Contributions}
This work implements a scenario in which there are some agents that estimate a cost function using their own information and those of other agents; they use a \textit{Distributed Sub-gradient Method} to update their own estimate and, in particular, they resolve a \textit{Multinomial Logistic Regression} problem.\\

The first step was to create a MATLAB script that solves a quadratic optimization problem using a gradient method. In this script it has been \textit{simulated} a distributed approach in order to test the effectiveness of the method saw in Distributed Subgradient Methods for Multi-Agent Optimization \cite{CITATION:1}. MATLAB was only used in the prototype phase, because it doesn't allow real parallel computations. After the confirmation that the approach was working, it started the implementation of the algorithm in Python3 using the Message Passing Interface.\\
The quadratic form used was 
\begin{equation} \tag{I}
x^{T}Qx + r^{T}x
\end{equation}. \\
This form was used only to test the convergence of the method.\\
After established that, considering that the Supervised Learning problem known as Multinomial Logistic Regression gives as output a probability value for every considered class, it was necessary to implement the softmax function. 
\begin{equation} \tag{II}
g_i\left(\theta\right):=\sum_{k=1}^{K}{1\{y^{(i)}=e_k\}\log{\left( \frac{exp(\theta^{(k)^\top}x^{(i)})}{\sum_{k=1}^{K}{exp( \theta^{(j)^\top}x )}} \right)}}
\end{equation} \cite{CITATION:3}. \\
The formula saw in \ref{EQ1.7} was minimized in a centralized setup using MATLAB, and the result was compared to the one of the Python distributed program.\\
It was seen that the algorithm was converging, several tests were executed to find the optimal values for the step-size.\\
The present work is divided into two chapters. In Chapter \ref{Cap1}, it is introduced the theory behind the problem and it is visualized and commented the implementation code. In Chapter \ref{Cap2} there are the results of simulations with some considerations.
% \section*{Organization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% CAPITOLO  %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Problem and its implementation} \label{Cap1}

\section{Theory of the problem} \label{Sec1.1}
\subsection {Distributed Subgradient Methods for Multi-Agent Optimization} \label{Subsec1.1.1}
In this problem there are $m$ agents that cooperatively minimize a common additive cost. The general optimization problem is:\\
\begin{equation} \label{costfunct}
min \quad \sum\limits_{i=1}^{m} f_{i} \left( x \right) \qquad subject \ to \quad x \in \mathbb{R}^n,
\end{equation}
where $f_i : \mathbb{R}^n \longrightarrow \mathbb{R}$ is the cost function of agent $i$, known only by the agent $i$, and $x \in \mathbb{R^n}$ is the decision vector. It is assumed that:
\begin{itemize} 
\item the cost function is convex;
\item the agents are distributed over a time-varying topology;
\item the graph $\left(V,E_\infty\right)$ is connected, where $E_\infty$ is the set of edges $\left(j,i\right)$ representing agent pairs communicating directly an indefinite number of times;
\item there is not communication delay.
\end{itemize} 
Every agent $i$ generates and maintains an estimate of the optimal decision vector based on information concerning its own cost function and exchanges this estimate with its neighbours at discrete times $t_0, t_1, t_2, ...$. A weights matrix is associated to the communication graph, and its elements are defined as follows:
\[
	\begin{cases}
		> 0, & \text{if } (i,j) \in E(k) \\
		0, & \text{otherwise}
	\end{cases}
\]
Each agent $j$ that receives an information by a neighbour agent $i$ weights this information by multiplying it by $a_i^j(k) \in \mathbb{R}$. Then the update of the estimate of the optimal solution is update according to:
\begin{equation} \label{update}
x^i\left(k+1\right) = \sum_{j=1}^{m}{a_j^i\left(k\right)x^i\left(k\right)-a^i\left(k\right)d_i\left(k\right)}
\end{equation}
where $\alpha^i(k)>0$ is the step-size used by agent $i$ and the vector $d_i(k)$ is a sub-gradient of objective function $f_i(x)$ calculated at $x=x^i(k)$. \cite{CITATION:1}

\subsection {Multinomial Logistic Regression} \label{Subsec1.1.2}
The problem to be solved is a Supervised Learning problem called Multinomial Logistic Regression, also known as Softmax Regression, and it generalizes the more common Logistic Regression. The difference between them is that in the former there are several classes to be considered, in the latter, there are only two classes (or equivalently a binary class).\\
The problem to be solved is to find a set of coefficients based on a given dataset to predict the belonging class for an unseen set of features, while minimizing a cost function. The dataset is composed of \textit{N} labelled examples $\{(x^{(1)}, y^{(1)}), ..., (x^{(N)}, y^{(N)})\}$. Each $x^{(i)} \in R^{d_{x}}$ for $i=1, ..., N$ is composed of some features which represent the value upon which we base the estimation of the belonging class, while $y^{(i)} \in R^{d_{y}}$ is the belonging class for the \textit{i-th} example, and can be a values in $\{1, ..., K\}$.

Given a single training example $(x^{(i)}, y^{(i)})$, the definition of the cost function is:
\begin{equation}
f_i\left(\omega\right):=\left|\left|h_\omega\left(x^{(i)}\right)-y^{(i)}\right|\right|^2
\end{equation}
where the $\omega \in R^{d_{x}}$ are the weights of the hypothesis function $h_{\omega}$. The overall cost function can be defined as:
\begin{equation}
f\left(\omega\right):=\sum_{i=1}^{N}{f_i\left(\omega\right)}
\end{equation}
We solve the problem by finding the solution of the following optimization problem:
\begin{equation}
\omega^*:=\arg\min_\omega f\left(\omega\right)
\end{equation}
In the Multinomial Logistic Regression, a common choice for the hypothesis function is the following:
\begin{equation}
h_\theta=\frac{1}{\sum_{j=1}^{K}{exp\left(\theta^{(j)^\top}x\right)}}\begin{bmatrix}exp\left(\theta^{(1)\top}x\right)  \\ \vdots \\ exp\left(\theta^{(K)\top}x\right) \end{bmatrix}
\end{equation}
where the weights $\omega = \theta = (\theta^{(1)}, ..., \theta^{(K)}) \in R^{d_{x}}$. \\
Using this function, the solution of the problem is given by finding:
\begin{equation}\label{EQ1.7}
\theta^*=\arg\min_\theta -\sum_{i=1}^{N}{g_i(\theta)}
\end{equation}
with
\begin{equation} \label{EQ1.8}
g_i\left(\theta\right):=\sum_{k=1}^{K}{1\{y^{(i)}=e_k\}\log{\left( \frac{exp(\theta^{(k)^\top}x^{(i)})}{\sum_{k=1}^{K}{exp( \theta^{(j)^\top}x )}} \right)}}
\end{equation}
where \textbf{1\{$\cdot$\}} being the \textit{indicator function}.\cite{CITATION:2}

\subsection {Pseudocode} \label{Subsec1.1.3}
\begin{algorithm}
\caption{}
\begin{algorithmic} [1]
\State \textit{Stop Rules:}
\State $\left|\left|\theta_{k+1} - \theta_k\right|\right|  \leq \varepsilon \qquad \varepsilon$ fixed
\State Number of maximum iterations reached
\State \textbf{Start:}
\State Fix initial conditions for each node $\theta_i(0) = [0 \quad ... \quad 0]^T$
\State Define the Adjacency Matrix, Weights Matrix, $\alpha^i = \alpha$ constant for each iteration
\While{No stop rule is true, each node $i$ does:} 
    \State calculate $\nabla f_i$
    \For {each neighbour j}
        \State $\theta_i(k+1) = \theta_i(k+1) + a^i_j(k) \theta^j(k)$
    \EndFor
    \State $\theta_i(k+1) = \theta_i(k+1) - \alpha \nabla f_i$
\EndWhile
\State \textbf{Result:}
\State Each node $i$ should converge to $\theta^*$
\State The minimum of function is $\sum \limits_{i=1}^{m}f_i(x^*)$
\end{algorithmic}
\end{algorithm}


\section {Code Implementation} \label{Sec1.2}

Here is defined and explained the Python imlementation that solves the problem. The solution has been
implemented using: $numpy$ library which computes all vector and matrix operation such as transposition, product, division,
summation; $networkx$ which creates and manages adjacency matrices for all agent; $matplotlib$ that plots the results
with data from the test and training phases. At first, the code checks if all the paramethers are valid,
then it starts to create the environment, the adjacency matrix and it initializes the local variables where
the data will be saved. The weights depend on how many in-neighbours each agent has. The number of in-neighbours for each agent can be passed as a paramether at launch, by specifying it with -k . \\

The adjacency matrix is created by the \textit{createAdjM} function. It makes a communication graph using world\_d as number of
mpi agents, n\_edges  (setted by default as 1), phi that is simply a phase inserted into
graph which just shift the connection, by default is 0 (TODO: la parte di phi non mi convince). The first $for$
cycle sets the number of agents that the system has, then edges are
computed as follows:
\begin{itemize}
    \item The sum j + k + phi + 1 means the position of edge in the
    graph where item j is the current row, k is the count of agent 
    that the agent j will send a message, phi is the phase and just
    shift the agent that j will send a message and the "+1" 

    \item The instruction $ if \ e >= world\_d $  checks if the sum is over the number of
    agents and if is true just subtracts this one

    \item Instead $ if \ e \ $==$ \  j $ removes the hypothetical unnecessary self loop.
\end{itemize}


Loss softmax function,\textit{loss\_softmax} gets as parameter the current state(\textit{all\_theta}), the cardinality of
iris set (\textit{category\_count}), the agent dataset (\textit{personal\_dataset}) and a \textit{CONSTANT\_TO\_SUBTRACT}, a
constant to prevent overflow.\\
The algorithm wants to calculate the $\displaystyle\sum_{i=0}^{number\_of\_agents} f_{i}(x)$ and this function calculate the
agent \textit{i} $f(x)$. This is done as follows: for every row in the personal dataset, the algorithm computes the
denominator that is the sum over all exponential. Then it computes, category by category, row by row, the logarithm of ratio
between the sum previously calculated and the exponential of the row. After that, there's the summation of all calculated
elements.

\begin{lstlisting}
def loss_softmax(all_theta, category_count, personal_dataset, CONSTANT_TO_SUBTRACT):
    the_sum = 0

    for index in range(0, len(personal_dataset)):
        denominator = 0

        for theta in all_theta:
            denominator = denominator + np.exp(np.dot(theta, personal_dataset[index][0:4]) - CONSTANT_TO_SUBTRACT)

        for category in range(0, category_count):

            if category == personal_dataset[index][4]:
                _exp = np.exp(np.dot(all_theta[category], personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)
                _log = np.log(np.divide(_exp, denominator))
                the_sum = the_sum - _log

    return the_sum
\end{lstlisting}

In the function \textit{gradient\_softmax} there is implemented the gradient of softmax equation. It is calculated similarly as the function mentioned before: calculate in a first time the sum of all exponential theta and then sum for
each coefficient, subtract from one that coefficient and finally subtract the dataset normalized with that to the respective
theta.

\begin{lstlisting}
def gradient_softmax(all_theta, category_count):

    thetas = np.zeros(dimensions)

    for index in range(0, len(personal_dataset)):
        denominator = 0

        for theta in all_theta:
            denominator = denominator + np.exp(np.dot(theta, personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)

        for category in range(0, category_count):
            coeff = 0

            if category == personal_dataset[index][4]:
                coeff = 1

            _exp = np.exp(np.dot(all_theta[category], personal_dataset[index][:4]) - CONSTANT_TO_SUBTRACT)
            coeff = coeff - np.divide(_exp, denominator)
            thetas[category] = thetas[category] - ((1/len(personal_dataset)) * np.multiply(personal_dataset[index][:4], coeff))

    return thetas
\end{lstlisting}

\subsection {working.py}

In this file is implemented the main algorithm where the loss function is minimized and the consensus is reached.\\

The complete iris training set is loaded, and some environment variables are setted like the number of agents. Then the dataset is splitted in equal parts to all agents and each one gets its own piece and it prints how many row it has.

Every agent creates the same communication directed graph with number of agents and number of in connection. Then state and
loss variable are created, setted to 0 of \textit{MAX\_ITERATIONS} size. In order to get weight the messages, all in-neighbours
are found and the variable \textit{weight} is setted as the average. If the function name inserted is "quadratic" Q and r
variables are created randomly. \textit{epsilon\_reached} and \textit{buff} are epsilon checker variable that say to agent
when they have to exit from the loop (if epsilon is reached).


This $for$ cycle calculates the consensus. For every $iters$, is calculated the new "diminishing" alpha; message(s) are sent
and received, then local variable are weighted. In order to solve consensus to desiderated function, the three implemented
ones are inserted into an $if$ clause, and the right function is called. After that, the calculated gradient is multiplied by
alpha and then new state is calculated. Then $loss function$ is called and if $\left\lVert XX[tt] - XX[tt-1] \right\rVert
\leq epsilon$ then buff is true and rank 0 check if all agent has reached the epsilon condition; if true it sends a broadcast 
message with a $true$ value to say to all that the cycle is done.

\begin{lstlisting}
for tt in range(1, MAX_ITERATIONS - 1):

    if alpha_type == "diminishing":
        alpha = psi_coefficient * (1 / tt) ** alpha_coefficient
    else:
        alpha = alpha_coefficient

    # Update with my previous state
    u_i = np.multiply(XX[tt - 1], weight)

    # Send the state to neighbors
    for node in adj.successors(rank):
        world.send(XX[tt - 1], dest=node)

    # Update with state of all nodes before me
    for node in adj.predecessors(rank):
        u_i = u_i + world.recv(source=node) * weight

    # Go in the opposite direction with respect to the gradient
    gradient = 0

    if function_name == "softmax":
        gradient = func.gradient_softmax(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

    elif function_name == "quadratic":
        gradient = func.gradient_quadratic(XX[tt - 1], category_n, dimensions, personal_dataset, Q, r)

    elif function_name == "exponential":
        gradient = func.gradient_exponential(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

     #print(gradient)

    grad = np.multiply(alpha, gradient)

    for i in range(0, dimensions[0]):
        u_i[i] = np.subtract(u_i[i], grad[i])

    # Store  my new state
    XX[tt] = u_i

    if function_name == "softmax":
        losses[tt] = func.loss_softmax(XX[tt], category_n, personal_dataset, CONSTANT_TO_SUBTRACT)

    elif function_name == "quadratic":
        losses[tt] = func.loss_quadratic(XX[tt], category_n, dimensions, personal_dataset, Q, r)

    elif function_name == "exponential":
        losses[tt] = func.loss_exponential(XX[tt - 1], category_n, dimensions, personal_dataset, CONSTANT_TO_SUBTRACT)

    # Checking epsilon reached condition
    if np.linalg.norm(np.subtract(XX[tt], XX[tt - 1])) < epsilon:
        buff = True

    # Rank 0 get all epsilon and check if all reached it
    buffer = world.gather(buff, root=0)

    # If true it set epsilon reached
    if rank == 0:
        if False not in buffer:
            epsilon_reached = True

    # Send epsilon reached to all agents
    epsilon_reached = world.bcast(epsilon_reached, root=0)

    # Check if all agent have reached epsilon condition and then exit from loop
    if epsilon_reached:
        if rank == 0:
            print("Exiting at iteration ", tt, "/", MAX_ITERATIONS, "Condition on epsilon reached")
            sys.stdout.flush()

        break

    if tt in range(0, MAX_ITERATIONS, 100):
        if rank == 0:
            print("Iteration ", tt, "/", MAX_ITERATIONS)
            sys.stdout.flush()
    ITERATION_DONE = tt
\end{lstlisting}

When consensus is reached, the theta values are printed to user, then all data are sent to rank 0 for centralized
calculations and plot result.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% CAPITOLO 2 %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Results of simulations} \label{Cap2}
	To verify the correctness of the software, a couple of simulations were run, divided into two parts:
\begin{itemize}
	\item Minimization of the Softmax function to prove the convergence to the optimal value
	\item Application of the minimization algorithm to find the optimal coefficients and prediction on the test dataset
\end{itemize}

\section{Minimization of the Softmax function}
The simulation has been carried out using a random directed graph made up of 17 agents, as shown in figure \ref{graph_17_agents}. \\
\begin{figure}[hb]
	\centering
	{\includegraphics[scale=.55]{figs/Graph}}
	\caption{Communication graph used for the simulation.}
	\label{graph_17_agents}
\end{figure}

For completing this simulation, a diminishing step-size has been used, with the following formulation:
\begin{equation}
	\alpha^k = 0.01 \left( \dfrac{1}{k} \right) ^{0.4}
\end{equation}
with $k$ indicating the current iteration.\\
The problem to be solved is the one formulated in \ref{EQ1.7}. Let's suppose to indicate the whole dataset as $S$. Each agent $i$ can access to a limited set $s_i$ of examples contained in $S$. To each agent is given a set $s_i$, chosen as:
\begin{equation}
	\label{dataset_condition}
	S = \bigcup\limits_{i=1}^{17} s_i
\end{equation}
In the simulation, the training set $S$ is composed by 120 examples, split into set $s_i$ of 6 or 7 examples, chosen in order to equation \ref{dataset_condition} hold.  \\
The iterations run are 15000, sufficient enough to see the function approaching the convergence, but not sufficient enough to reach the minimum value of the function, calculated with MATLAB to be $8.945$. The figure \ref{log_cost} shows in a logarithmic scale how the algorithm tends to minimize the cost value at each iteration. \\
\begin{figure}[hb]
	\centering
	\includegraphics[scale=0.4]{figs/cost_log_scale}
	\caption{Value of the normalized cost function in a logarithmic scale over all the iterations. }
	\label{log_cost}
\end{figure}

The value of the cost function is shown in figure \ref{lin_cost} in a linear scale too, so it can be seen how the algorithm approaches the minimum value $\Theta^{*}$ in order to have the minimum of the problem \ref{EQ1.7}.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{figs/cost_linear_scale}
	\caption{Value of the normalized cost function in a linear scale. }
	\label{lin_cost}
\end{figure}

As can be seen in figure \ref{avg_consensus}, all the agents try to reach the consensus for each component of the local minimum of the problem. 

To better see the consensus, in this simulation the initial condition have been chosen to be random integer number between $-10$ and $+10$. With this choice is more visible the trend if the agents that try to reach consensus.

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[scale=.4]{figs/theta_1_3_overall}
		\caption{Overall trend over all the iterations}
		\label{avg_consensus:overall}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[scale=.4]{figs/theta_1_3_detail}
		\caption{Detail for the first 140 iterations}
		\label{avg_consensus:detail}
	\end{subfigure}
	\caption{Consensus on the third component of $\Theta_1$}
	\label{avg_consensus}
\end{figure}


\section{Dataset, graph description and minimization function} \label{Sec2.1}
This dataset is composed of 150 instances, 120 used for training, the rest for tests. The instances contain 3 classes, each representing a type of Iris flower. Every instance has 4 features, sepal length, sepal width, petal length, petal width expressed in $cm$. We tried different types of graphs. These graphs are all strongly connected and the weight matrices for the nodes are doubly stochastic, as per the assumptions of convergence of the algorithm described in Chapter \ref{Cap1}. The results discussed in this chapter, if not differently noted, refer to cyclic graphs with a variable number of nodes. The program can minimize all kinds of loss functions. As shown in Chapter \ref{Sec1.2}, the quadratic and exponential functions can also be used. These last 2 functions don't guarantee useful results and/or convergence. The minimization function used in this chapter is the one described in Chapter \ref{Subsec1.1.2}, softmax.

\section{Performance} \label{Sec2.2}
There are some key factors that influence \textit{the computational time}, \textit{the numbers of iterations necessary} and \textit{the accuracy of the results}.\\

\subsection{Number of nodes} \label{Subsec2.2.1}
The Python program, thanks to the MPI platform, is capable of running on an arbitrary number of nodes. It was tested on as little as 2 nodes to as many as 60 nodes, which means that every node was processing the data of 2 instances (120 instances divided into 60 nodes). The best performances are obtained when the number of nodes corresponds to the number of physical cores of the machine where it runs. When the number of nodes exceeds greatly the number of physical cores, the resources are oversubscribed. In this case, the performances degrade notably as the nodes compete for cache and memory and the processors' schedulers are put in a difficult situation. On a 4-core test machine, a computation with 5000 iterations and 30 nodes is done in 5 minutes. The same machine can do the same number of iterations, but with 60 nodes, in 15 minutes. Therefore, the following tests will be shown on a 4 nodes set-up. \\

\subsection{Epsilon} \label{Subsec2.2.2}
This is a small constant used as stop condition. If the result of the current calculation differs less than epsilon from the previous, the algorithm is stopped.

\subsection{Learning rate} \label{Subsec2.2.3}
The step-size alpha plays a big role in the speed of convergence of the algorithm. There are 3 kinds of step-size. Fixed, diminishing and adaptive (Armijo). For reasons not discussed in this paper, it's not possible to use Armijo rule in a distributed problem.

\subsection{Fixed step-size} \label{Subsec2.2.4}
 We will first deal with a simpler fixed step-size. With an epsilon equal to $0.001\  (10^{-3})$:\\
\begin{scriptsize}
\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|}
\hline
\textbf{Value of fixed step-size} & \textbf{Iteration required} & \textbf{Execution time in s} & \textbf{Wrong guesses o.30}\\
\hline\hline
0.5 & overflow & alpha too big & -\\
\hline
0.1 & \textgreater 10000 & \textgreater 15 & 2\\
\hline
0.05 & \textgreater 10000 & \textgreater 15 & 1\\
\hline
0.01 & 1968 & 2.8 & 1\\
\hline
0.005 & 1558 & 2.3 & 1\\
\hline
0.001 & 2114 & 3.1 & 0\\
\hline
0.0005 & 1619 & 2.3 & 2\\
\hline
0.0001 & 527 & 0.7 & 14\\
\hline
\end{tabular} \\
\end{center}
\end{scriptsize}

These results show a general truth about the step-size. If it is too little, the learning process proceeds in a very slow way and it requires a huge amount of iterations. If the learning rate is too high, the gradient descent will most probably overshoot the minimum and it will not converge. Through trial and error, the step-size 0.001 was identified, it allows reaching good performance and accuracy. In fact, in only 3.1 seconds, we can make predictions with no errors, using our 30 instances test dataset.

\subsection{Diminishing step-size} \label{Subsec2.2.5}
The diminishing step-size implemented in the code is in this form:
TODO: SISTEMARE
\\
\begin{equation}
\alpha = const \left( \frac{1}{tt} \right) exp
\end{equation}
Again, several tests were run by tweaking the multiplying constant and the exponent.\\ \\

\begin{scriptsize}
\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|>{\centering\arraybackslash}m{1.7cm}|}
\hline
\scriptsize{\textbf{psi\_coeff}} & \scriptsize{\textbf{alpha\_exp coefficient}} & \scriptsize{\textbf{Iteration required}} & \scriptsize{\textbf{Execution time in s}} & \scriptsize{\textbf{Wrong guesses o. 30}}\\
\hline \hline
1 & 0.01 & overflow & - & -\\
\hline
1 & 0.1 & overflow & - & -\\
\hline
0.1 & 0.01 & \textgreater 10000 & \textgreater 15 & 1\\
\hline
0.1 & 0.5 & 349 & 0.5 & 0\\
\hline
0.1 & 0.1 & \textgreater 10000 & \textgreater 16 & 1\\
\hline
0.01 & 0.01 & 1852 & 2.7 & 1\\
\hline
0.01 & 0.1 & 1259 & 1.8 & 1\\
\hline
\end{tabular}\\
\end{center}
\end{scriptsize}

\noindent The best result is obtained in only 349 iterations, with 0.1 and 0.5 as multiplicative constant and exponent respectively. This is done in roughly half of a second, obtaining no error. The accuracy is worst then the previous result, but this is obtained in a fraction of the time needed to obtain 0 error with a fixed step-size. A difference of 2 or 3 seconds may not seem important using the Iris Dataset, with a small amount of calculations. In a set-up where a bigger number of calculations and bigger dataset are involved, one may appreciate the advantages of this faster approach.




TODO: GRAFICI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% SVILUPPI FUTURI %%%%%%
\chapter*{Conclusions} % and future developments}
\addcontentsline{toc}{chapter}{Conclusions} %  and future developments}
In this work it has been resolved a Multinomial Logistic Regression problem using MPI in Python. Each agent used a Distributed Sub-gradient method to update its own estimate of optimal solution.
%% Tutte le considerazioni finali sintetiche si fanno in base alla tabella dei risultati del capitolo 2.
%%%%%%%%%%%%%%%%%%%%%%%%%%

% %%%% APPENDIX %%%%%
% \appendix
% \chapter{Appendix title}
% %%%%%%%%%%%%%%%%%%%%

%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%
\bibliography{bibliography}{}
\bibliographystyle{plain}   
\addcontentsline{toc}{chapter}{Bibliography}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
